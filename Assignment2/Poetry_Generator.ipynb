{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Poetry Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TMgKJI45189"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFIL6wy9HJcn"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_W413bW52zW"
      },
      "source": [
        "vowels = list('aeioóuyąę')\n",
        "compacted_vowels = ['i' + x for x in vowels if x != 'i']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7f-gZFR53ll"
      },
      "source": [
        "def load_supertags(path):\n",
        "\n",
        "    file = open(path, 'r')\n",
        "    word_to_tag = {}\n",
        "    tag_to_words = {}\n",
        "\n",
        "    for line in tqdm(file):\n",
        "\n",
        "        word, tag = line.split(\" \")\n",
        "        if tag[-1] == \"\\n\": tag = tag[:-1]\n",
        "\n",
        "        word_to_tag[word.lower()] = tag\n",
        "\n",
        "        if tag in tag_to_words:\n",
        "            tag_to_words[tag].append(word)\n",
        "        else:\n",
        "            tag_to_words[tag] = [word]\n",
        "            \n",
        "    \n",
        "    file.close()\n",
        "    return word_to_tag, tag_to_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxqe3SSn54l_"
      },
      "source": [
        "def load_bigrams_and_create_bitags_to_bigram_occurrence(path, word_to_tag, amount):\n",
        "    \n",
        "    file = open(path, 'r')\n",
        "    bigramtag_to_bigram_occurrence = {}\n",
        "    acc = 0\n",
        "\n",
        "    for iter, line in tqdm(enumerate(file)):\n",
        "\n",
        "        oc, word1, word2 = line.lower().split(\" \")\n",
        "\n",
        "        if word2[-1] == \"\\n\": word2 = word2[:-1]\n",
        "\n",
        "        if word1 not in word_to_tag.keys() or word2 not in word_to_tag.keys(): continue\n",
        "    \n",
        "        if oc == 1: continue\n",
        "        #if iter == amount: break\n",
        "\n",
        "        acc += int(oc)\n",
        "\n",
        "        key = (word_to_tag[word1], word_to_tag[word2])\n",
        "\n",
        "        if key in bigramtag_to_bigram_occurrence.keys():\n",
        "            bigramtag_to_bigram_occurrence[key].append(((word1, word2), int(oc)))\n",
        "        else:\n",
        "            bigramtag_to_bigram_occurrence[key] = [((word1, word2), int(oc))] \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return bigramtag_to_bigram_occurrence, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T56HdZPW55hm"
      },
      "source": [
        "def load_unigrams(path):\n",
        "\n",
        "    file = open(path, 'r')\n",
        "    unigrams = {}\n",
        "    acc = 0\n",
        "\n",
        "    for line in tqdm(file):\n",
        "        \n",
        "        word, oc = line.split()\n",
        "        acc += int(oc)\n",
        "        unigrams[word] = oc\n",
        "    \n",
        "    return unigrams, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpAbw1B1HPh8"
      },
      "source": [
        "# Poetry Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XFGtihA563E"
      },
      "source": [
        "def count_vowels(word):\n",
        "\n",
        "    res = 0\n",
        "    for iter, letter in enumerate(word):\n",
        "\n",
        "        if letter in vowels:\n",
        "            res+=1\n",
        "            if word[iter:iter+2] in compacted_vowels:\n",
        "                res -= 1\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09A9E4VE57X2"
      },
      "source": [
        "def is_ryme(word_1, word_2):\n",
        "\n",
        "    sylabes_1 = count_vowels(word_1)\n",
        "    sylabes_2 = count_vowels(word_2)\n",
        "\n",
        "    while len(word_1) > 0:\n",
        "        if word_1[0] in vowels:\n",
        "            sylabes_1 -= 1\n",
        "\n",
        "        if word_1[:2] in compacted_vowels:\n",
        "            word_1 = word_1[1:]\n",
        "\n",
        "        if sylabes_1 - 2 < 0:\n",
        "            break\n",
        "\n",
        "        word_1 = word_1[1:]\n",
        "    \n",
        "\n",
        "    while len(word_2) > 0:\n",
        "\n",
        "        if word_2[0] in vowels:\n",
        "            sylabes_2 -= 1\n",
        "        \n",
        "        if word_2[:2] in compacted_vowels:\n",
        "            word_2 = word_2[1:]\n",
        "        \n",
        "        if sylabes_2 - 2 < 0:\n",
        "            break\n",
        "        \n",
        "        word_2 = word_2[1:]\n",
        "    \n",
        "\n",
        "    return word_1 == word_2\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_FiK2Xt59em"
      },
      "source": [
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "def choose_word_softmax(words):\n",
        "\n",
        "    occurrences = np.array([word[1] for word in words], dtype=np.float64)\n",
        "\n",
        "    occurrences = (occurrences - min(occurrences)) / (max(occurrences) - min(occurrences) + 0.0001)\n",
        "\n",
        "    number_of_words = len(words)\n",
        "    probs = softmax(occurrences)\n",
        "    word_idx = np.random.choice(number_of_words , size = 1, p = probs)[0]\n",
        "\n",
        "    return words[word_idx][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehSJK2qE5-aJ"
      },
      "source": [
        "def test_sentence_and_return_partition(sent):\n",
        "\n",
        "    correct = False\n",
        "    syl = 0\n",
        "    partition = []\n",
        "\n",
        "    if sent[-1] == '\\r': sent = sent[:-1]\n",
        "\n",
        "    sent = ''.join([char.lower() for char in sent if char not in string.punctuation]).split()\n",
        "\n",
        "    for word in sent:\n",
        "        \n",
        "        if word in word_to_tag.keys():\n",
        "            syl += count_vowels(word)\n",
        "            partition.append((count_vowels(word), word_to_tag[word]))\n",
        "            \n",
        "    if len(partition) == len(sent) and syl == 13: \n",
        "        correct = True\n",
        "\n",
        "    return (correct, partition, sent[-1])\n",
        "\n",
        "\n",
        "def sample_partition_with_tags(text):\n",
        "    \n",
        "    correct_1 = False\n",
        "    correct_2 = False\n",
        "    correct_ryme = False\n",
        "    while not correct_1 or not correct_2 or not correct_ryme:\n",
        "        partition = []\n",
        "        syl = 0\n",
        "        sentidx = random.randint(0, len(text)-2)\n",
        "        sent_1 = text[sentidx]\n",
        "        sent_2 = text[sentidx+1]\n",
        "        \n",
        "        if len(sent_1) < 2 or len(sent_2) < 2: continue\n",
        "\n",
        "        (correct_1, partition_1, last_word_1) = test_sentence_and_return_partition(sent_1)\n",
        "        (correct_2, partition_2, last_word_2) = test_sentence_and_return_partition(sent_2)\n",
        "\n",
        "        correct_ryme = is_ryme(last_word_1, last_word_2)\n",
        "\n",
        "    \n",
        "    return partition_1, sent_1, partition_2, sent_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4B644Ij5_oP",
        "outputId": "9ef939cd-5678-4b74-d5e8-72b651c14e5c"
      },
      "source": [
        "word_to_tag, tag_to_words = load_supertags('/content/drive/My Drive/Colab Notebooks/NLP/Dane/Copy of supertags.txt')\n",
        "unigrams, unigrams_all_oc = load_unigrams('/content/drive/My Drive/Colab Notebooks/NLP/Dane/unigrams.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1781994it [00:03, 501929.12it/s]\n",
            "3591114it [00:16, 221438.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6b23nTOGOib",
        "outputId": "68d5e3aa-852f-4c78-d421-13c7820d53c8"
      },
      "source": [
        "text = open('/content/drive/My Drive/Colab Notebooks/NLP/Dane/PT.txt', 'rb').read().decode(\"utf-8\").lower().split('\\n')\n",
        "bigramtag_to_bigram_occurrence, bigrams_all_oc = load_bigrams_and_create_bitags_to_bigram_occurrence('/content/poleval_2grams.txt', word_to_tag, 100000000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59134224it [06:14, 157930.25it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaSCLhzf7uxG"
      },
      "source": [
        "import random\n",
        "\n",
        "def pmi(word_1, word_2, oc):\n",
        "\n",
        "    res = 0\n",
        "    if word_1 in unigrams.keys() and word_2 in unigrams.keys():\n",
        "        res = np.log((oc/bigrams_all_oc)/((int(unigrams[word_1])/unigrams_all_oc)*\n",
        "                                          (int(unigrams[word_2])/unigrams_all_oc)))\n",
        "    return res\n",
        "\n",
        "def find_grammatically_similar_sentence_bigram(part_1, part_2, bitag_to_bigram_occurence, recall, col=False):\n",
        "\n",
        "    res = []\n",
        "    err = 0\n",
        "\n",
        "    len_first = len(part_1)\n",
        "    part_1.extend(part_2)\n",
        "\n",
        "    sen_part = part_1\n",
        "\n",
        "    if col:\n",
        "        f = pmi\n",
        "    else:\n",
        "        f = lambda x, y, z: z\n",
        "\n",
        "\n",
        "    while len(res) != len(sen_part):\n",
        "\n",
        "        if err >= recall:\n",
        "            return None\n",
        "\n",
        "        if len(res) < 2:\n",
        "            res = []\n",
        "            ### Generate first bigram\n",
        "            syl_1, tag_1 = sen_part[0]\n",
        "            syl_2, tag_2 = sen_part[1]\n",
        "            \n",
        "            if bitag_to_bigram_occurence.get((tag_1,tag_2)) is None: return None\n",
        "            \n",
        "            words = [((bigram[0], bigram[1]), f(bigram[0], bigram[1], int(oc))) for bigram, oc in \n",
        "                     bitag_to_bigram_occurence.get((tag_1,tag_2)) if count_vowels(bigram[0])==syl_1 and count_vowels(bigram[1])==syl_2]\n",
        "\n",
        "            if len(words) == 0: return None\n",
        "            pred_1, pred_2 = choose_word_softmax(words)\n",
        "            res.append(pred_1)\n",
        "            res.append(pred_2)\n",
        "\n",
        "        len_res = len(res) - 1\n",
        "\n",
        "        syl_1, tag_1 = sen_part[len_res]\n",
        "        syl_2, tag_2 = sen_part[len_res+1]\n",
        "\n",
        "        key = (tag_1, tag_2)\n",
        "\n",
        "        if bitag_to_bigram_occurence.get((tag_1,tag_2)) is None: return None\n",
        "\n",
        "        lw = res[-1]\n",
        "\n",
        "        if len(res) < len(sen_part) - 1:\n",
        "            words = [((bigram[0], bigram[1]), f(bigram[0], bigram[1], int(oc))) for bigram, oc \n",
        "                     in bitag_to_bigram_occurence.get((tag_1,tag_2)) if lw == bigram[0] and count_vowels(bigram[0])==syl_1 and count_vowels(bigram[1])==syl_2]\n",
        "        else:\n",
        "             words = [((bigram[0], bigram[1]), f(bigram[0], bigram[1], int(oc))) for bigram, oc \n",
        "                      in bitag_to_bigram_occurence.get((tag_1,tag_2)) if lw == bigram[0] and count_vowels(bigram[0])==syl_1 and count_vowels(bigram[1])==syl_2 and is_ryme(bigram[1], res[len_first-1])]\n",
        "\n",
        "        if len(words) == 0:\n",
        "            res = res[:-1]\n",
        "            err += 1\n",
        "        else:\n",
        "            pred_1, pred_2 = choose_word_softmax(words)\n",
        "            res.append(pred_2)\n",
        "    \n",
        "    return res   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9csMCUqTxQO",
        "outputId": "6635a910-8290-48c9-d331-b78492e440ff"
      },
      "source": [
        "for _ in tqdm(range(1000)):\n",
        "    res = None\n",
        "    while res == None:\n",
        "        partition_1, sent_1, partition_2, sent_2 = sample_partition_with_tags(text)\n",
        "\n",
        "        len_1 = len(partition_1)\n",
        "\n",
        "        res = find_grammatically_similar_sentence_bigram(partition_1, partition_2, bigramtag_to_bigram_occurrence, 50, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [1:09:40<00:00,  4.18s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eV6kMMnGrac"
      },
      "source": [
        "# Words Occurences Poetry Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoo42EecYBQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccf8608-441c-4e93-ba51-94218459e38f"
      },
      "source": [
        "gen(70, col=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['było', 'to', 'właśnie', 'sprawnie', 'na', 'jej', 'narodzinach']\n",
            "['nadal', 'szkolono', 'tylko', 'o', 'tych', 'przeprosinach']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMeXETOKhb1r",
        "outputId": "82b4ba5f-63d5-4ca6-9a2b-db07b3b465b9"
      },
      "source": [
        "gen(70, col=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gotowanie', 'czy', 'zbieżne', 'czy', 'było', 'darmowe']\n",
            "['że', 'ropy', 'osiągnęły', 'jak', 'szkoły', 'państwowe']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbBK50Y0hkK_",
        "outputId": "23db591a-0363-4776-87b7-4645dfbbc9e8"
      },
      "source": [
        "gen(70, col=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['kazały', 'mu', 'się', 'stadia', 'zgodnie', 'podkreślano']\n",
            "['ten', 'zysk', 'niewielki', 'wtedy', 'o', 'grobach', 'składano']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n1voZsAG1bX"
      },
      "source": [
        "# PMI Poetry Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twJgO8DYhke3",
        "outputId": "77b90875-8b95-4e56-dce5-be9c1a14649c"
      },
      "source": [
        "gen(70, col=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['w', 'złudnej', 'rzeczywistości', 'przez', 'pudła', 'i', 'kwiatka']\n",
            "['dlatego', 'nim', 'dotarli', 'za', 'centrem', 'do', 'płatka']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnlxZOgxhlxA",
        "outputId": "3e6c6663-eb48-4a64-98ed-bb910b022d37"
      },
      "source": [
        "gen(70, col=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['niby', 'gruszka', 'ze', 'spania', 'i', 'piękna', 'zadbana']\n",
            "['a', 'cesarska', 'od', 'błędu', 'jak', 'kwaśna', 'odmiana']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5khABjUhmYB",
        "outputId": "eae32596-0da9-455b-c73b-99b57b1319d5"
      },
      "source": [
        "gen(70, col=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['to', 'owczarek', 'to', 'michnik', 'robert', 'z', 'oferentów']\n",
            "['nie', 'chomikuj', 'go', 'z', 'kratki', 'bez', 'osiem', 'segmentów']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}