{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text classification for authorship.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA5FBy0UWM9O"
      },
      "source": [
        "import regex\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEfAT7Hecc88"
      },
      "source": [
        "!tar -xvf '/content/drive/My Drive/Colab Notebooks/NLP/Dane/dane_pozytywizm.tgz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s0XTVUu3sv3"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC40YeZxV_Jj"
      },
      "source": [
        "def preprocess(path, stop_words, author):\n",
        "\n",
        "    text = open(path, 'rb').read().decode(\"utf-8\").lower()\n",
        "\n",
        "    text = regex.sub(u\"[^ \\n\\p{Latin},:\\-'.?!]\", \" \",text)\n",
        "    text = regex.sub(u\"[,]\", \" ,\",text)\n",
        "    text = regex.sub(u\"[ \\n]+\", \" \", text)\n",
        "    sentences = [regex.split(' ', regex.sub(r\"^ \",\"\",l)) for l in regex.split('\\.|\\?|!|:',text)] \n",
        "    sentences = [[word for word in sentence if word not in stop_words] for sentence in sentences]\n",
        "    sentences = [sentence for sentence in sentences if len(sentence) > 2]\n",
        "\n",
        "    return sentences, np.full(len(sentences), author)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNvxdiExkVrA"
      },
      "source": [
        "path_to_stop_words = '/content/drive/My Drive/Colab Notebooks/NLP/Dane/stop_words.txt'\n",
        "\n",
        "stop_words = {word for word in open(path_to_stop_words,'rb').read().decode('utf-8').split('\\n')}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfvmumeXoTV",
        "outputId": "d5567c38-bfb8-4021-fe0a-15971c4897cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Orzeszkowa corpus\n",
        "path_orz = '/content/dane_pozytywistyczne/korpus_orzeszkowej.txt'\n",
        "sentences_orz, labels_orz = preprocess(path_orz, stop_words, 0)\n",
        "print(\"Orzeszkowa - number of sentences: {}\".format(len(sentences_orz)))\n",
        "# Prus corpus\n",
        "path_pr = '/content/dane_pozytywistyczne/korpus_prusa.txt'\n",
        "sentences_pr, labels_pr = preprocess(path_pr, stop_words, 1)\n",
        "print(\"Prus - number of sentences: {}\".format(len(sentences_pr)))\n",
        "# Sienkiewicz corpus\n",
        "path_sie = '/content/dane_pozytywistyczne/korpus_sienkiewicza.txt'\n",
        "sentences_sie, labels_sie = preprocess(path_sie, stop_words, 2)\n",
        "print(\"Sienkiewicz - number of sentences: {}\".format(len(sentences_sie)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Orzeszkowa - number of sentences: 12284\n",
            "Prus - number of sentences: 12166\n",
            "Sienkiewicz - number of sentences: 5363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPxg5a0GmFM5"
      },
      "source": [
        "# Train/Val split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfGSdLSAuJeR",
        "outputId": "c197fea2-ac0c-4647-d64b-766478cc89af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = np.concatenate((sentences_orz,sentences_pr,sentences_sie))\n",
        "labels = np.concatenate((labels_orz,labels_pr,labels_sie))\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.05, random_state=42)\n",
        "\n",
        "print(\"Train/Val split\")\n",
        "print('Train size: {}'.format(len(X_train)))\n",
        "print('Val size: {}'.format(len(X_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train/Val split\n",
            "Train size: 28322\n",
            "Val size: 1491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x-r7BJ0mJrW"
      },
      "source": [
        "# Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7ETLF7cmO5N"
      },
      "source": [
        "## Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXLc_qGYnssh",
        "outputId": "8c4dd93b-41e6-46e6-82e3-808310d26f80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def build_dict(sentences):\n",
        "    res_dict = {}\n",
        "    iter = 0 \n",
        "    for sen in sentences:\n",
        "        for word in sen:\n",
        "            if word not in res_dict:\n",
        "                res_dict[word] = iter\n",
        "                iter += 1\n",
        "\n",
        "    return res_dict\n",
        "\n",
        "words_to_keys = build_dict(X_train)\n",
        "keys_to_words = {value: key for (key, value) in words_to_keys.items()}\n",
        "\n",
        "print(\"Vocabulary size: {}\".format(len(words_to_keys.keys())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 54287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyyxRpBPq9bc"
      },
      "source": [
        "## Word occurences/sentences length/comma occurences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1CSwUSCpK8P",
        "outputId": "bc9237b1-8091-40a6-b888-0a92b2b68445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "def build_features(words_to_keys, dataset, labels):\n",
        "\n",
        "    number_of_authors = np.unique(labels)\n",
        "\n",
        "    sentences_length = np.zeros((4, len(number_of_authors)))\n",
        "\n",
        "    commas = np.zeros((1, len(number_of_authors)))\n",
        "\n",
        "    occurences = np.zeros((len(words_to_keys.keys()), len(number_of_authors)))\n",
        "\n",
        "    for sen, label in zip(dataset, labels):\n",
        "        for word in set(sen):\n",
        "            occurences[words_to_keys[word], label] += 1\n",
        "\n",
        "\n",
        "        sen_len = len(sen)\n",
        "        if sen_len <= 5:\n",
        "            sentences_length[0, label] += 1\n",
        "        elif 5 < sen_len <= 10:\n",
        "            sentences_length[1, label] += 1\n",
        "        elif 10 < sen_len <= 15:\n",
        "            sentences_length[2, label] += 1\n",
        "        elif 15 < sen_len:\n",
        "            sentences_length[3, label] += 1\n",
        "        \n",
        "    return occurences, sentences_length, commas\n",
        "\n",
        "oc, sentences_length, commas = build_features(words_to_keys, X_train, y_train)\n",
        "\n",
        "#Orzechowska : 0 | Prus : 1 | Sienkiewicz : 2\n",
        "words_occurences_dataframe = pd.DataFrame(oc, index = words_to_keys.keys(), columns=['0', '1', '2'])\n",
        "sentences_length_dataframe = pd.DataFrame(sentences_length, index = ['l5', 'm5l10','m10l15','m15'], columns=['0', '1', '2'])\n",
        "df = pd.concat([words_occurences_dataframe / words_occurences_dataframe.sum(0), sentences_length_dataframe / sentences_length_dataframe.sum(0)])\n",
        "\n",
        "\n",
        "df.tail(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>zwiÄ…zuje</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>drga</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bÅ‚yszczy</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wywoÅ‚aÅ‚o</th>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>powyrywaÅ‚</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zawiasÃ³w</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>l5</th>\n",
              "      <td>0.275268</td>\n",
              "      <td>0.321268</td>\n",
              "      <td>0.299863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m5l10</th>\n",
              "      <td>0.279126</td>\n",
              "      <td>0.367077</td>\n",
              "      <td>0.306518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m10l15</th>\n",
              "      <td>0.180626</td>\n",
              "      <td>0.181590</td>\n",
              "      <td>0.185555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m15</th>\n",
              "      <td>0.264981</td>\n",
              "      <td>0.130066</td>\n",
              "      <td>0.208064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0         1         2\n",
              "zwiÄ…zuje   0.000000  0.000000  0.000021\n",
              "drga       0.000000  0.000000  0.000021\n",
              "bÅ‚yszczy   0.000000  0.000000  0.000021\n",
              "wywoÅ‚aÅ‚o   0.000008  0.000000  0.000000\n",
              "powyrywaÅ‚  0.000000  0.000010  0.000000\n",
              "zawiasÃ³w   0.000000  0.000010  0.000000\n",
              "l5         0.275268  0.321268  0.299863\n",
              "m5l10      0.279126  0.367077  0.306518\n",
              "m10l15     0.180626  0.181590  0.185555\n",
              "m15        0.264981  0.130066  0.208064"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2YNFqk03mJr"
      },
      "source": [
        "# Naive_bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fuVnNQJyW3X"
      },
      "source": [
        "\"FROM MACHINE LEARNING CLASS ASSIGNMENT 2\"\n",
        "\n",
        "def naive_bayes(sent, authors, df, dict_W):\n",
        "    \"\"\"Returns the most probable language of a sentence\"\"\"\n",
        "\n",
        "    # Try working with log-probabilities.\n",
        "    # to prevent taking log(0) you can e.g. add a very small amount (1e-100)\n",
        "    # to each tabulated frequency.\n",
        "    df_log = np.log(df+1e-100)\n",
        "    \n",
        "    # normalize the sentence: remove spaces and punctuations, take lower case\n",
        "\n",
        "    probs = {}\n",
        "    res = 1\n",
        "    for author in authors:\n",
        "        log_prob = 0\n",
        "        for word in sent:\n",
        "            if word in dict_W:\n",
        "                log_prob += df_log.loc[word][author]\n",
        "        \n",
        "        #['l5', 'm5l10','m10l15','m15l20']\n",
        "        sen_len = len(sent)\n",
        "        if sen_len <= 5:\n",
        "            log_prob += df_log.loc['l5'][author]\n",
        "        elif 5 < sen_len <= 10:\n",
        "            log_prob += df_log.loc['m5l10'][author]\n",
        "        elif 10 < sen_len <= 15:\n",
        "            log_prob += df_log.loc['m10l15'][author]\n",
        "        elif 15 < sen_len:\n",
        "            log_prob += df_log.loc['m15'][author]\n",
        "\n",
        "        probs[author] = np.exp(log_prob)\n",
        "        res += probs[author] \n",
        "        \n",
        "\n",
        "    # TODO compute language probabilitie and order from most to least probable\n",
        "    probs = [(x, y/res) for x,y in sorted(probs.items(), key=lambda x: x[1], reverse=True)][0]\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCEjNMcENdZG"
      },
      "source": [
        "## VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDVcAv6N0od5"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def error_bayes(X_test, y_test, df, words_to_keys):\n",
        "    res = 0\n",
        "    for sen, label in zip(X_test, y_test):\n",
        "        pred = naive_bayes(sen, [0, 1, 2], df, words_to_keys.keys())\n",
        "        if pred[0] == label:\n",
        "            res += 1\n",
        "    \n",
        "    print(\"Error: {}\".format(1-res/len(y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbMSf6Z51HP4",
        "outputId": "79ca7aad-87a0-4311-a92e-5ba253902e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "error_bayes(X_val, y_val, df, words_to_keys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.22132796780684105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPablSX0Ngyh"
      },
      "source": [
        "## TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-gE4svJb4B",
        "outputId": "58f745f2-8df4-4118-c45e-b34e4defd247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "paths = '/content/dane_pozytywistyczne/testy1/'\n",
        "\n",
        "test_X = []\n",
        "test_y = []\n",
        "\n",
        "for i, path in enumerate(os.listdir(paths)):\n",
        "    if len(regex.findall(\"orzeszkowej\", path)) == 1:\n",
        "        sentences, labels = preprocess(os.path.join(paths,path), stop_words, 0)\n",
        "    if len(regex.findall(\"prusa\", path)) == 1:\n",
        "        sentences, labels = preprocess(os.path.join(paths,path), stop_words, 1)\n",
        "    if len(regex.findall(\"sienkiewicza\", path)) == 1:\n",
        "        sentences, labels = preprocess(os.path.join(paths,path), stop_words, 2)\n",
        "    test_X += sentences\n",
        "    test_y += labels.tolist()\n",
        "    print(\"\\n\",path)\n",
        "    error_bayes(sentences, labels, df, words_to_keys)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " test_sienkiewicza15.txt\n",
            "Error: 0.6774193548387097\n",
            "\n",
            " test_prusa0.txt\n",
            "Error: 0.4590163934426229\n",
            "\n",
            " test_sienkiewicza11.txt\n",
            "Error: 0.6421052631578947\n",
            "\n",
            " test_orzeszkowej7.txt\n",
            "Error: 0.42000000000000004\n",
            "\n",
            " test_sienkiewicza41.txt\n",
            "Error: 0.7948717948717949\n",
            "\n",
            " test_orzeszkowej.txt\n",
            "Error: 0.34042553191489366\n",
            "\n",
            " test_sienkiewicza17.txt\n",
            "Error: 0.8690476190476191\n",
            "\n",
            " test_sienkiewicza3.txt\n",
            "Error: 0.7894736842105263\n",
            "\n",
            " test_sienkiewicza25.txt\n",
            "Error: 0.42666666666666664\n",
            "\n",
            " test_prusa14.txt\n",
            "Error: 0.273972602739726\n",
            "\n",
            " test_sienkiewicza47.txt\n",
            "Error: 0.7397260273972603\n",
            "\n",
            " test_sienkiewicza35.txt\n",
            "Error: 0.8734177215189873\n",
            "\n",
            " test_prusa20.txt\n",
            "Error: 0.07462686567164178\n",
            "\n",
            " test_orzeszkowej19.txt\n",
            "Error: 0.22916666666666663\n",
            "\n",
            " test_orzeszkowej13.txt\n",
            "Error: 0.46153846153846156\n",
            "\n",
            " test_prusa8.txt\n",
            "Error: 0.33333333333333337\n",
            "\n",
            " test_sienkiewicza33.txt\n",
            "Error: 0.7605633802816901\n",
            "\n",
            " test_prusa12.txt\n",
            "Error: 0.2666666666666667\n",
            "\n",
            " test_prusa16.txt\n",
            "Error: 0.18604651162790697\n",
            "\n",
            " test_sienkiewicza29.txt\n",
            "Error: 0.8873239436619719\n",
            "\n",
            " test_orzeszkowej9.txt\n",
            "Error: 0.4716981132075472\n",
            "\n",
            " test_orzeszkowej11.txt\n",
            "Error: 0.54\n",
            "\n",
            " test_sienkiewicza37.txt\n",
            "Error: 0.868421052631579\n",
            "\n",
            " test_orzeszkowej21.txt\n",
            "Error: 0.42000000000000004\n",
            "\n",
            " test_prusa2.txt\n",
            "Error: 0.41333333333333333\n",
            "\n",
            " test_sienkiewicza13.txt\n",
            "Error: 0.6582278481012658\n",
            "\n",
            " test_orzeszkowej15.txt\n",
            "Error: 0.5714285714285714\n",
            "\n",
            " test_prusa6.txt\n",
            "Error: 0.33333333333333337\n",
            "\n",
            " test_sienkiewicza5.txt\n",
            "Error: 0.6031746031746033\n",
            "\n",
            " test_prusa26.txt\n",
            "Error: 0.18644067796610164\n",
            "\n",
            " test_sienkiewicza53.txt\n",
            "Error: 0.8444444444444444\n",
            "\n",
            " test_prusa36.txt\n",
            "Error: 0.2816901408450704\n",
            "\n",
            " test_prusa30.txt\n",
            "Error: 0.18666666666666665\n",
            "\n",
            " test_orzeszkowej1.txt\n",
            "Error: 0.31999999999999995\n",
            "\n",
            " test_prusa38.txt\n",
            "Error: 0.09459459459459463\n",
            "\n",
            " test_sienkiewicza31.txt\n",
            "Error: 0.8392857142857143\n",
            "\n",
            " test_sienkiewicza43.txt\n",
            "Error: 0.8333333333333334\n",
            "\n",
            " test_sienkiewicza49.txt\n",
            "Error: 0.7551020408163265\n",
            "\n",
            " test_sienkiewicza45.txt\n",
            "Error: 0.7887323943661972\n",
            "\n",
            " test_orzeszkowej17.txt\n",
            "Error: 0.17460317460317465\n",
            "\n",
            " test_prusa40.txt\n",
            "Error: 0.07352941176470584\n",
            "\n",
            " test_prusa24.txt\n",
            "Error: 0.12244897959183676\n",
            "\n",
            " test_prusa28.txt\n",
            "Error: 0.11111111111111116\n",
            "\n",
            " test_prusa32.txt\n",
            "Error: 0.19047619047619047\n",
            "\n",
            " test_sienkiewicza21.txt\n",
            "Error: 0.8314606741573034\n",
            "\n",
            " test_prusa22.txt\n",
            "Error: 0.1875\n",
            "\n",
            " test_orzeszkowej3.txt\n",
            "Error: 0.24\n",
            "\n",
            " test_prusa18.txt\n",
            "Error: 0.2717391304347826\n",
            "\n",
            " test_sienkiewicza9.txt\n",
            "Error: 0.6285714285714286\n",
            "\n",
            " test_sienkiewicza39.txt\n",
            "Error: 0.8615384615384616\n",
            "\n",
            " test_sienkiewicza1.txt\n",
            "Error: 0.5862068965517242\n",
            "\n",
            " test_prusa10.txt\n",
            "Error: 0.3584905660377359\n",
            "\n",
            " test_prusa4.txt\n",
            "Error: 0.3114754098360656\n",
            "\n",
            " test_prusa34.txt\n",
            "Error: 0.2533333333333333\n",
            "\n",
            " test_sienkiewicza27.txt\n",
            "Error: 0.6911764705882353\n",
            "\n",
            " test_sienkiewicza19.txt\n",
            "Error: 0.788235294117647\n",
            "\n",
            " test_sienkiewicza7.txt\n",
            "Error: 0.7833333333333333\n",
            "\n",
            " test_sienkiewicza51.txt\n",
            "Error: 0.5593220338983051\n",
            "\n",
            " test_sienkiewicza23.txt\n",
            "Error: 0.7294117647058824\n",
            "\n",
            " test_orzeszkowej5.txt\n",
            "Error: 0.49275362318840576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Ho9DBVVUFY",
        "outputId": "5355de27-7f1f-460c-9465-ca227d1bc82a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "error_bayes(test_X, test_y, df, words_to_keys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.4969450101832994\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}